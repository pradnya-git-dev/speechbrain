############################################################################
# Model: Tacotron2
# Tokens: Raw characters (English text)
# losses: Transducer
# Training: LJSpeech
# Authors: Georges Abous-Rjeili, Artem Ploujnikov, Yingzhi Wang
# ############################################################################


###################################
# Experiment Parameters and setup #
###################################
seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]
output_folder: !ref ./results/tacotron2/<seed>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt
epochs: 150
keep_checkpoint_interval: 50
use_tensorboard: False

log_audio_samples: True
vocoder: !PLACEHOLDER
vocoder_savedir: !PLACEHOLDER

spk_emb_mel_spec_encoder: !PLACEHOLDER

###################################
# Progress Samples                #
###################################
# Progress samples are used to monitor the progress
# of an ongoing training session by outputting samples
# of spectrograms, alignments, etc at regular intervals

# Whether to enable progress samples
progress_samples: True

# The path where the samples will be stored
progress_sample_path: !ref <output_folder>/samples
# The interval, in epochs. For instance, if it is set to 5,
# progress samples will be output every 5 epochs
progress_samples_interval: 1
# The sample size for raw batch samples saved in batch.pth
# (useful mostly for model debugging)
progress_batch_sample_size: 3

#################################
# Data files and pre-processing #
#################################
data_folder: !PLACEHOLDER # e.g, /localscratch/ljspeech

use_vctk_data: True
vctk_data_folder: !ref <data_folder>/vctk_sr22050
vctk_valid_uttids: ['p374_418_mic1',
 'p263_030_mic1',
 's5_293_mic1',
 'p275_205_mic1',
 'p259_043_mic1',
 'p252_140_mic1',
 'p226_064_mic1',
 'p329_037_mic1',
 'p284_130_mic1',
 'p265_279_mic1',
 'p360_241_mic1',
 'p301_149_mic1',
 'p280_383_mic1',
 'p250_429_mic1',
 'p341_243_mic1',
 'p239_292_mic1',
 'p233_043_mic1',
 'p231_361_mic1',
 'p257_017_mic1',
 'p363_188_mic1',
 'p264_120_mic1',
 'p254_350_mic1',
 'p334_245_mic1',
 'p237_211_mic1',
 'p264_464_mic1',
 'p232_136_mic1',
 'p323_089_mic1',
 'p253_099_mic1',
 'p333_258_mic1',
 'p267_323_mic1',
 'p364_032_mic1',
 'p257_134_mic1',
 'p285_285_mic1',
 'p232_121_mic1',
 'p232_193_mic1',
 'p283_094_mic1',
 'p340_383_mic1',
 'p246_151_mic1',
 'p232_318_mic1',
 'p274_051_mic1',
 'p295_174_mic1',
 'p262_392_mic1',
 'p303_256_mic1',
 'p230_386_mic1',
 'p334_016_mic1',
 'p360_414_mic1',
 'p282_368_mic1',
 'p285_104_mic1',
 'p265_278_mic1',
 'p226_084_mic1',
 'p275_185_mic1',
 'p263_042_mic1',
 'p288_245_mic1',
 'p280_351_mic1',
 'p299_030_mic1',
 'p292_347_mic1',
 'p264_392_mic1',
 'p334_409_mic1',
 'p267_142_mic1',
 'p246_237_mic1',
 'p317_269_mic1',
 'p232_147_mic1',
 'p376_259_mic1',
 'p310_035_mic1',
 'p229_217_mic1',
 'p361_012_mic1',
 'p267_107_mic1',
 'p295_412_mic1',
 'p271_195_mic1',
 'p252_067_mic1',
 'p258_053_mic1',
 'p374_296_mic1',
 'p265_327_mic1',
 'p266_245_mic1',
 'p241_092_mic1',
 'p250_274_mic1',
 'p316_396_mic1',
 'p282_102_mic1',
 'p300_146_mic1',
 'p228_302_mic1',
 'p334_397_mic1',
 'p313_141_mic1',
 'p243_293_mic1',
 'p229_298_mic1',
 'p268_359_mic1',
 'p240_048_mic1',
 'p334_224_mic1',
 'p243_386_mic1',
 'p330_325_mic1',
 'p333_373_mic1',
 'p263_468_mic1',
 'p230_057_mic1',
 'p237_134_mic1',
 'p253_214_mic1',
 'p251_364_mic1',
 'p268_142_mic1',
 'p257_414_mic1',
 'p272_240_mic1',
 'p247_351_mic1',
 'p263_164_mic1',
 'p260_094_mic1',
 'p251_289_mic1',
 'p229_160_mic1',
 'p362_392_mic1',
 'p278_089_mic1',
 'p269_355_mic1',
 'p288_060_mic1',
 'p336_357_mic1',
 'p323_239_mic1',
 'p274_122_mic1',
 'p258_055_mic1',
 'p273_235_mic1',
 'p259_459_mic1',
 'p257_110_mic1',
 'p285_370_mic1',
 'p295_383_mic1',
 'p301_397_mic1',
 'p300_062_mic1',
 'p330_380_mic1',
 'p364_176_mic1',
 'p360_147_mic1',
 'p249_251_mic1',
 'p274_341_mic1',
 'p239_033_mic1',
 'p288_170_mic1',
 'p293_098_mic1',
 'p307_008_mic1',
 'p270_378_mic1',
 'p230_096_mic1',
 'p233_064_mic1',
 'p286_342_mic1',
 'p329_382_mic1',
 'p262_112_mic1',
 'p376_001_mic1',
 'p333_036_mic1',
 'p227_114_mic1',
 'p330_216_mic1',
 'p292_349_mic1',
 'p310_104_mic1',
 'p299_285_mic1',
 'p244_187_mic1',
 'p232_255_mic1',
 'p260_269_mic1',
 'p286_283_mic1',
 'p275_007_mic1',
 'p263_082_mic1',
 'p239_086_mic1',
 'p273_244_mic1',
 'p227_217_mic1',
 'p250_430_mic1',
 'p252_077_mic1',
 'p254_403_mic1',
 'p270_082_mic1',
 'p272_054_mic1',
 'p241_110_mic1',
 'p246_330_mic1',
 'p268_144_mic1',
 'p269_099_mic1',
 'p297_105_mic1',
 'p269_268_mic1',
 'p244_402_mic1',
 'p341_351_mic1',
 'p285_361_mic1',
 'p275_298_mic1',
 'p306_288_mic1',
 'p298_162_mic1',
 'p298_059_mic1',
 'p257_078_mic1',
 'p237_179_mic1',
 'p279_012_mic1',
 'p264_481_mic1',
 'p271_400_mic1',
 'p312_213_mic1',
 'p330_330_mic1',
 'p360_160_mic1',
 'p237_070_mic1',
 'p265_113_mic1',
 'p311_257_mic1',
 'p317_379_mic1',
 'p306_101_mic1',
 'p316_019_mic1',
 'p272_320_mic1',
 's5_386_mic1',
 'p269_169_mic1',
 'p298_339_mic1',
 'p340_411_mic1',
 'p284_241_mic1',
 'p286_227_mic1',
 'p247_006_mic1',
 'p333_071_mic1',
 'p278_038_mic1',
 'p271_387_mic1',
 'p247_057_mic1',
 'p270_375_mic1',
 'p293_159_mic1',
 's5_301_mic1',
 'p266_358_mic1',
 'p345_061_mic1',
 'p263_429_mic1',
 'p233_226_mic1',
 'p232_263_mic1',
 'p274_410_mic1',
 'p271_118_mic1',
 'p300_118_mic1',
 'p277_376_mic1',
 'p280_304_mic1',
 'p278_279_mic1',
 'p313_256_mic1',
 'p280_365_mic1',
 'p307_209_mic1',
 'p257_035_mic1',
 'p310_156_mic1',
 'p313_268_mic1',
 'p297_135_mic1',
 'p364_304_mic1',
 'p256_293_mic1',
 'p304_007_mic1',
 'p351_244_mic1',
 'p243_011_mic1',
 'p311_192_mic1',
 'p364_046_mic1',
 'p282_100_mic1',
 'p275_191_mic1',
 'p336_408_mic1',
 'p351_199_mic1',
 'p236_407_mic1',
 'p246_206_mic1',
 'p297_390_mic1',
 'p299_339_mic1',
 'p236_183_mic1',
 'p236_119_mic1',
 'p271_200_mic1',
 'p334_219_mic1',
 'p240_361_mic1',
 'p278_168_mic1',
 'p374_190_mic1',
 'p307_236_mic1',
 'p299_156_mic1',
 'p269_196_mic1',
 'p298_117_mic1',
 'p330_236_mic1',
 'p270_232_mic1',
 'p314_176_mic1',
 'p229_215_mic1',
 'p330_181_mic1',
 'p258_299_mic1',
 'p301_058_mic1',
 'p308_402_mic1',
 'p229_381_mic1',
 'p252_108_mic1',
 'p239_384_mic1',
 'p333_305_mic1',
 'p311_382_mic1',
 'p376_373_mic1',
 'p374_404_mic1',
 'p229_275_mic1']
vctk_test_spk_ids: ["p261", "p225", "p294", "p347", "p238", "p234", "p248", "p335", "p245", "p326", "p302"]

train_json: !ref <save_folder>/train.json
valid_json: !ref <save_folder>/valid.json
test_json: !ref <save_folder>/test.json

train_speaker_embeddings_pickle: !ref <save_folder>/train_speaker_embeddings.pickle
valid_speaker_embeddings_pickle: !ref <save_folder>/valid_speaker_embeddings.pickle
test_speaker_embeddings_pickle: !ref <save_folder>/test_speaker_embeddings.pickle

splits: ["train", "valid", "test"]
# split_ratio: [80, 10, 10]

train_splits: []
valid_splits: []
test_splits: []

skip_prep: False

# Use the original preprocessing from nvidia
# The cleaners to be used (applicable to nvidia only)
text_cleaners: ['english_cleaners']

################################
# Audio Parameters             #
################################
sample_rate: !PLACEHOLDER
hop_length: 256
win_length: 1024
n_mel_channels: 80
n_fft: 1024
mel_fmin: 0.0
mel_fmax: 8000.0
mel_normalized: False
power: 1
norm: "slaney"
mel_scale: "slaney"
dynamic_range_compression: True

################################
# Speaker Embedding Parameters #
################################

spk_emb_size: 192
spk_emb_sample_rate: !PLACEHOLDER

################################
# Optimization Hyperparameters #
################################
learning_rate: 0.0001
weight_decay: 0.000006
batch_size: 32 #minimum 2
mask_padding: True
guided_attention_sigma: 0.2
guided_attention_weight: 75.0
guided_attention_weight_half_life: 10.
guided_attention_hard_stop: 50
gate_loss_weight: 1.0
compute_spk_emb_loss: False
spk_emb_loss_weight: 1.0

train_dataloader_opts:
  batch_size: !ref <batch_size>
  drop_last: False  #True #False
  num_workers: 8
  collate_fn: !new:models.MSTacotron2.TextMelCollate
    speaker_embeddings_pickle: !ref <train_speaker_embeddings_pickle>

valid_dataloader_opts:
  batch_size: !ref <batch_size>
  drop_last: False
  num_workers: 8
  collate_fn: !new:models.MSTacotron2.TextMelCollate
    speaker_embeddings_pickle: !ref <valid_speaker_embeddings_pickle>

test_dataloader_opts:
  batch_size: !ref <batch_size>
  drop_last: False
  num_workers: 8
  collate_fn: !new:models.MSTacotron2.TextMelCollate
    speaker_embeddings_pickle: !ref <test_speaker_embeddings_pickle>

################################
# Model Parameters and model   #
################################
n_symbols: 148 #fixed depending on symbols in textToSequence
symbols_embedding_dim: 448

# Encoder parameters
encoder_kernel_size: 5
encoder_n_convolutions: 3
encoder_embedding_dim: 448

# Decoder parameters
# The number of frames in the target per encoder step
n_frames_per_step: 1
decoder_rnn_dim: 896
prenet_dim: 224
max_decoder_steps: 1000
gate_threshold: 0.5
p_attention_dropout: 0.1
p_decoder_dropout: 0.1
decoder_no_early_stopping: False

# Attention parameters
attention_rnn_dim: 896
attention_dim: 112

# Location Layer parameters
attention_location_n_filters: 32
attention_location_kernel_size: 31

# Mel-post processing network parameters
postnet_embedding_dim: 448
postnet_kernel_size: 5
postnet_n_convolutions: 5

mel_spectogram: !name:models.MSTacotron2.mel_spectogram
  sample_rate: !ref <sample_rate>
  hop_length: !ref <hop_length>
  win_length: !ref <win_length>
  n_fft: !ref <n_fft>
  n_mels: !ref <n_mel_channels>
  f_min: !ref <mel_fmin>
  f_max: !ref <mel_fmax>
  power: !ref <power>
  normalized: !ref <mel_normalized>
  norm: !ref <norm>
  mel_scale: !ref <mel_scale>
  compression: !ref <dynamic_range_compression>

#model
model: !new:models.MSTacotron2.Tacotron2
  mask_padding: !ref <mask_padding>
  n_mel_channels: !ref <n_mel_channels>
  # symbols
  n_symbols: !ref <n_symbols>
  symbols_embedding_dim: !ref <symbols_embedding_dim>
  # encoder
  encoder_kernel_size: !ref <encoder_kernel_size>
  encoder_n_convolutions: !ref <encoder_n_convolutions>
  encoder_embedding_dim: !ref <encoder_embedding_dim>
  # attention
  attention_rnn_dim: !ref <attention_rnn_dim>
  attention_dim: !ref <attention_dim>
  # attention location
  attention_location_n_filters: !ref <attention_location_n_filters>
  attention_location_kernel_size: !ref <attention_location_kernel_size>
  # decoder
  n_frames_per_step: !ref <n_frames_per_step>
  decoder_rnn_dim: !ref <decoder_rnn_dim>
  prenet_dim: !ref <prenet_dim>
  max_decoder_steps: !ref <max_decoder_steps>
  gate_threshold: !ref <gate_threshold>
  p_attention_dropout: !ref <p_attention_dropout>
  p_decoder_dropout: !ref <p_decoder_dropout>
  # postnet
  postnet_embedding_dim: !ref <postnet_embedding_dim>
  postnet_kernel_size: !ref <postnet_kernel_size>
  postnet_n_convolutions: !ref <postnet_n_convolutions>
  decoder_no_early_stopping: !ref <decoder_no_early_stopping>
  # speaker embeddings
  spk_emb_size: !ref <spk_emb_size>

guided_attention_scheduler: !new:speechbrain.nnet.schedulers.StepScheduler
  initial_value: !ref <guided_attention_weight>
  half_life: !ref <guided_attention_weight_half_life>

criterion: !new:models.MSTacotron2.Loss
  gate_loss_weight: !ref <gate_loss_weight>
  guided_attention_weight: !ref <guided_attention_weight>
  guided_attention_sigma: !ref <guided_attention_sigma>
  guided_attention_scheduler: !ref <guided_attention_scheduler>
  guided_attention_hard_stop: !ref <guided_attention_hard_stop>
  spk_emb_loss_weight: !ref <spk_emb_loss_weight>

modules:
  model: !ref <model>

#optimizer
opt_class: !name:torch.optim.Adam
  lr: !ref <learning_rate>
  weight_decay: !ref <weight_decay>

#epoch object
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
  limit: !ref <epochs>

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
  save_file: !ref <train_log>

#annealing_function
lr_annealing: !new:speechbrain.nnet.schedulers.IntervalScheduler
  intervals:
    - steps: 6000
      lr: 0.00005
    - steps: 8000
      lr: 0.00003
    - steps: 10000
      lr: 0.00001

#checkpointer
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: !ref <save_folder>
  recoverables:
    model: !ref <model>
    counter: !ref <epoch_counter>
    scheduler: !ref <lr_annealing>

progress_sample_logger: !new:speechbrain.utils.train_logger.ProgressSampleLogger
  output_path: !ref <progress_sample_path>
  batch_sample_size: !ref <progress_batch_sample_size>
  formats:
    raw_batch: raw


tacotron2_model_path: !PLACEHOLDER
pretrained_separator: !new:speechbrain.utils.parameter_transfer.Pretrainer
  collect_in: !ref <save_folder>
  loadables:
    model: !ref <model>
  paths:
    model: !ref <tacotron2_model_path>/model.ckpt